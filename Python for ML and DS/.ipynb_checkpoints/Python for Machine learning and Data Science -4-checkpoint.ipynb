{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PytzMLS2018: Python for ML and DS Research - Pandas\n",
    "\n",
    "<center>**Anthony Faustine (sambaiga@gmail.com)**</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Pandas library \n",
    "\n",
    "http://pandas.pydata.org/\n",
    "\n",
    "[Panda](http://pandas.pydata.org/pandas-docs/stable/) : a python package providing fast, flexible, and\n",
    "expressive data structures for data analysis.\n",
    "- A fundamental high-level building block for doing practical,\n",
    "real world data analysis in Python.\n",
    "- Designed to work with relational or labeled data or both."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Panda first load the panda library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from CSV file into dataframe\n",
    "\n",
    "You can read data from a CSV file using the **read_csv** function. By default, it assumes that the fields are comma-separated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/primary/primary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all the columns in the DataFrame\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# We can use the len function again here to see how many rows there are in the dataframe: 163\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How big is this dataframe (rows, columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let view the first few rows \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that read_csv automatically considered the first row in the file to be a header row.\n",
    "We can override default behavior by customizing some the arguments, like header, names or index_col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View Last 6 rows\n",
    "data.tail(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Adding and Droping column\n",
    "Let us add another column to the primary dataframe. Suppose we want to add total enrollment column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['TOTAL']=data['MALE']+ data[\"FEMALE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It clear from the above result we can perform arthmetic operation on pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Column\n",
    "\n",
    "We can  delete column in panda dataframe. Let us delete the TOTAL column in primary enrollment dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop('TOTAL', axis=1, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note:\n",
    " 1. **axis=1** denotes that we are referring to a column, not a row\n",
    " 2. **inplace=True** means that the changes are saved to the df right away"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Slicing Subsets of Rows and Columns in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting a single column - returns a 'series'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.REGION\n",
    "# You can aslo use data['REGION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To select column as data frame\n",
    "data[['DISTRICT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting multiple columns - returns a dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['REGION','DISTRICT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting rows by number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[15:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try  data[:8] and data[100:]\n",
    "data[:8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Position Based Selection of columns and lows\n",
    "Pandas allows us to use position based indexing implemented with iloc and loc: \n",
    ">**.loc** for label-based indexing\n",
    "\n",
    ">**.iloc** for positional indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To slice a specific column using label indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here is how to slice a column:\n",
    "data.loc[: , \"REGION\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use postion indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  To extract only a row you would do the inverse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To select range of row and column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Select first four rows(including header) and first three column (including SN)\n",
    "data.iloc[0:3,0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select only the specified range of column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,1:3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To select  different columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:,[0, 3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Subsetting Data Using Criteria\n",
    "We can also select a subset of our data using criteria. For example, we can select all rows that have female higher than 50000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.FEMALE > 50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can select all rows which are in Arusha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.REGION == 'ARUSHA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can select data based on criteria and choose which column to display. Example let select all districts with male erollment less than 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[data.MALE < 10000][['DISTRICT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Descriptive Statistics  From Data\n",
    "\n",
    "Descriptive statistics can give you great insight into the shape of each attribute. The **describe()** function on the Pandas DataFrame lists 8 statistical properties of each attribute:\n",
    "\n",
    "* Count\n",
    "* Mean\n",
    "* Standard Devaition\n",
    "* Minimum Value\n",
    "* 25th Percentile\n",
    "* 50th Percentile (Median)\n",
    "* 75th Percentile\n",
    "* Maximum Value\n",
    "\n",
    "For example to obtain the statistics summary  for Cities data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain descriptive statistics of a particular column use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['MALE'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Missing Data\n",
    "\n",
    "Real-world data is rarely clean and homogeneous. In particular, many interesting datasets will have some amount of data missing.\n",
    "\n",
    "Pandas treats **None** and **NaN** as essentially interchangeable for indicating missing or null values.\n",
    "\n",
    "**Pandas Methods for missing values:\n",
    "\n",
    "* isnull(): Generate a boolean mask indicating missing values\n",
    "* notnull(): Opposite of isnull()\n",
    "* dropna(): Return a filtered version of the data\n",
    "* fillna(): Return a copy of the data with missing values filled or imputed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Detecting null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Total missing values in each columns\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting rid of missing data points\n",
    "\n",
    "#### Drop all missing data\n",
    "\n",
    "``.dropna()``: will drop all rows that have any missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = data.dropna()\n",
    "clean_data.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filling null values\n",
    "\n",
    "Sometimes rather than dropping NA values, you'd rather replace them with a valid value. This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"FEMALE\"].fillna(data[\"FEMALE\"].mean(), inplace=True)\n",
    "data[\"MALE\"].fillna(data[\"MALE\"].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing Out Data to CSV\n",
    "\n",
    "We can use the **to_csv** command to do export a DataFrame in CSV format. We can save it to a different folder by adding the foldername and a slash to the file **.to_csv('foldername/filename.csv')**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save the dataset to harddisk\n",
    "#data.to_csv('Data/primary_atc.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "- [python4datascience-atc](https://github.com/pythontz/python4datascience-atc)\n",
    "- [PythonDataScienceHandbook](https://github.com/jakevdp/PythonDataScienceHandbook)\n",
    "- [DS-python-data-analysis](https://github.com/jorisvandenbossche/DS-python-data-analysis)\n",
    "* [Pandas & Seaborn - A guide to handle & visualize data elegantly](https://tryolabs.com/blog/2017/03/16/pandas-seaborn-a-guide-to-handle-visualize-data-elegantly/)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
